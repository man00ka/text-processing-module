{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "523e3a08-ec9b-4f2b-bff7-218242f55f1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DEMO ToxicityFilter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab27ed4-0b48-4b7f-9847-b5bf31b588d2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46e9a24-b2ee-43a6-947e-1594d7daa196",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ToxicityFilter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d654216-5317-4ce3-a5cb-a2ef10ac63ec",
   "metadata": {},
   "source": [
    "The ToxicityFilter submodule has **several components**:\n",
    "1. **ToxicityFilter**: A two-tiered approach using *word lists* as a quick, rule-based approach as a first stage and a a more **more sophisticated approach** by utilizing a module called [**detoxify**](https://github.com/unitaryai/detoxify) as a second stage.\n",
    "2. **SpanDetector**: Returns the span of toxic parts in a text. Can also **sanitize, tag and highlight** toxic span.\n",
    "\n",
    "The first import of ToxicityFilter might take a some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "080a95b3-b3df-4f76-a484-a95b14ccb098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TextProcessingModule.toxicity_filter import ToxicityFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8d3431c-42b1-49fb-9566-90c38dcf23d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When initializing ToxicityFilter() for the first time, a model is downloaded by detoxify\n",
    "# which might take a little while as well.\n",
    "toxicity_filter = ToxicityFilter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae6b4c0a-7490-4226-892e-071a934829af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(1, {'This is stupid!': 'stupid'})\n"
     ]
    }
   ],
   "source": [
    "# This will trigger the first filter stage.\n",
    "print(toxicity_filter.apply(\"This is stupid!\"))\n",
    "print(toxicity_filter.apply(\"This is stupid!\", verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfff6567-673e-44a6-b7f4-f4a6f210da9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(1, {'Detoxify: Toxicity above threshold!': {'Toxicity': 0.64452136, 'Threshold': 0.5}})\n"
     ]
    }
   ],
   "source": [
    "# This will trigger the second filter stage\n",
    "print(toxicity_filter.apply(\"Women are only good for cleaning the house!\"))\n",
    "print(toxicity_filter.apply(\"Women are only good for cleaning the house!\", verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a33961e-cf01-4719-a4fd-b118ff9503df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(1, {'Detoxify: Toxicity above threshold!': {'Toxicity': 0.23198009, 'Threshold': 0.1}})\n"
     ]
    }
   ],
   "source": [
    "# You can also adapt the threshold of the toxicity filter. Default = 0.5\n",
    "# It is strongly encouraged to dial it in on your specific use case.\n",
    "threshold = 0.1\n",
    "print(toxicity_filter.apply(\"Sheep are only good for cleaning the house!\", threshold))\n",
    "print(toxicity_filter.apply(\"Sheep are only good for cleaning the house!\", threshold, verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52978ea6-1945-45c4-9461-72e75dba30e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# This will *NOT* trigger any filter stage (which is a bit unfortunate imho)\n",
    "print(toxicity_filter.apply(\"Men are only good for cleaning the house!\"))\n",
    "print(toxicity_filter.apply(\"Men are only good for cleaning the house!\", verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3c7dfd6-ea4e-4b18-a6da-fb088b467e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Men are only good for cleaning the house!': {'toxicity': 0.018119397}}\n",
      "{'Men are only good for cleaning the house!': {'toxicity': 0.018119397, 'severe_toxicity': 0.00012027769, 'obscene': 0.00041868672, 'threat': 0.00018928485, 'insult': 0.00071454945, 'identity_attack': 0.0004367168}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxicity</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Men are only good for cleaning the house!</th>\n",
       "      <td>0.01812</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>0.00042</td>\n",
       "      <td>0.00019</td>\n",
       "      <td>0.00071</td>\n",
       "      <td>0.00044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           toxicity  severe_toxicity  obscene  \\\n",
       "Men are only good for cleaning the house!   0.01812          0.00012  0.00042   \n",
       "\n",
       "                                            threat   insult  identity_attack  \n",
       "Men are only good for cleaning the house!  0.00019  0.00071          0.00044  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# However, if you want to know what amount of toxicity was detected\n",
    "# despite beeing lower than the threshold you set, you can do\n",
    "# this like so:\n",
    "print(toxicity_filter.detoxify_filter.get_toxicity())  # Returns only the toxicity value\n",
    "\n",
    "# Or in even more detail:\n",
    "print(toxicity_filter.detoxify_filter.get_scores())  # Additionally returns the likelihood for different toxic categories\n",
    "\n",
    "# Or in a beautified form as pandas data frame:\n",
    "toxicity_filter.detoxify_filter.get_scores(as_dataframe=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebecb6a9-7fba-4269-8d7d-cdc6a3173334",
   "metadata": {},
   "source": [
    "## Separate usage of filter stages\n",
    "You can also use the filter stages on their own"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513535d6-a712-4fed-839f-9da4fbeb2599",
   "metadata": {},
   "source": [
    "### Word List Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25237ba9-d636-4fc7-a057-d70f61ad059f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TextProcessingModule.toxicity_filter import WordListFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe68e832-1fc3-4c82-ad09-68cd5a50b81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(1, {'This is stupid!': 'stupid'})\n"
     ]
    }
   ],
   "source": [
    "demo_text = \"This is stupid!\"\n",
    "word_list_filter = WordListFilter()  # You can also pass the path to your own word list.\n",
    "print(word_list_filter.apply(demo_text))  # Returns 1 when the filter is triggered and None otherwise.\n",
    "print(word_list_filter.apply(demo_text, verbose=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa8000f-7e18-4f7a-b5b7-5c6f6915e4da",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2762997c-8b80-426f-8fea-e25c62de7469",
   "metadata": {},
   "source": [
    "### Detoxify Filter\n",
    "When initialized for the first time, detoxify will **download a model from huggingface** which might take a little time and in the future uses the downloaded file automatically. You can also download the model separately and pass its path as `model` argument.\n",
    "\n",
    "You can load **different models** to use for this filter (see: https://github.com/unitaryai/detoxify).\n",
    "Default: `model='original'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18f6ba0a-ffd7-46b0-9553-88b1c1390d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TextProcessingModule.toxicity_filter import DetoxifyFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02cadeca-b708-4ae3-b8d4-21a1f44be6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "detoxify_filter = DetoxifyFilter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d0ec7b5-522e-4633-99a2-a00df33cfd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(1, {'Detoxify: Toxicity above threshold!': {'Toxicity': 0.9581592, 'Threshold': 0.5}})\n"
     ]
    }
   ],
   "source": [
    "print(detoxify_filter.apply(\"This is stupid!\"))\n",
    "print(detoxify_filter.apply(\"This is stupid!\", verbose=True))\n",
    "\n",
    "# Returns 1 if toxicity is greater than `threshold`, else 0 (toxicity <= `threshold`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef2ec31-a6e6-461f-9a6f-f01d2fc1dd2e",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9674ce98-6685-4253-8d42-e5b357a0a5fc",
   "metadata": {},
   "source": [
    "After applying the filter you can also view **toxicity score** and the scores of **different toxicity categories** like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9b3180f-0e04-4e8a-97bb-2b3d4afa32cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'This is stupid!': {'toxicity': 0.9581592}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show toxicity score\n",
    "detoxify_filter.get_toxicity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2edbe7c-e702-47b5-8364-755a58b52981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'This is stupid!': {'toxicity': 0.9581592,\n",
       "  'severe_toxicity': 0.0062750294,\n",
       "  'obscene': 0.3832781,\n",
       "  'threat': 0.0018581518,\n",
       "  'insult': 0.11622658,\n",
       "  'identity_attack': 0.0015853597}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show scores for different toxicity categories\n",
    "detoxify_filter.get_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8371ae2-f06e-4cc7-b85e-9483a2cca7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxicity</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>This is stupid!</th>\n",
       "      <td>0.95816</td>\n",
       "      <td>0.00628</td>\n",
       "      <td>0.38328</td>\n",
       "      <td>0.00186</td>\n",
       "      <td>0.11623</td>\n",
       "      <td>0.00159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 toxicity  severe_toxicity  obscene   threat   insult  \\\n",
       "This is stupid!   0.95816          0.00628  0.38328  0.00186  0.11623   \n",
       "\n",
       "                 identity_attack  \n",
       "This is stupid!          0.00159  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show scores as data frame\n",
    "detoxify_filter.get_scores(as_dataframe=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d7b895-a223-45ca-8893-899839c2077c",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8f52fc-89f8-4a48-a0df-f6a0d3dddd37",
   "metadata": {},
   "source": [
    "### Comparison of both filter stages\n",
    "For this test, we keep track of the results of both filters applied to several small texts using variables `results1` and `results2`.\n",
    "\n",
    "To also keep track of low-level results with more detail, we initialize both filters with `keep_results=True` to keep track of the detected tokens and toxicity. One could also set this on an existing instance via `set_keep_result(True)`.\n",
    "\n",
    "> [!NOTE]\n",
    "> Note that for `text3` the **word list filter triggers** while the **detoxify filter does not**, which might change when using a different model for detoxify.\n",
    "\n",
    "> [!NOTE]\n",
    "> Also note that for `text6` the **detoxify filter triggers**, although this represents more irony than toxic language.\n",
    "\n",
    "> [!NOTE]\n",
    "> Also note that the **word list filter is much faster**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b7690de-8e5d-4d3d-9d46-3f75451ac219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TextProcessingModule.toxicity_filter import WordListFilter, DetoxifyFilter\n",
    "\n",
    "word_list_filter = WordListFilter(keep_results=True)\n",
    "detoxify_filter = DetoxifyFilter(keep_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "486835bd-0130-4933-9013-e4f51097745d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14 ms, sys: 4.8 ms, total: 18.8 ms\n",
      "Wall time: 79.5 ms\n",
      "CPU times: user 2.35 s, sys: 428 ms, total: 2.78 s\n",
      "Wall time: 492 ms\n",
      "\n",
      "Results:\n",
      " * WordListFilter: [1, None, 1, 1, None, None, None]\n",
      " * DetoxifyFilter: [1, None, None, 1, 1, 1, None]\n"
     ]
    }
   ],
   "source": [
    "# Examples:\n",
    "text1 = \"This is shit!\"\n",
    "text2 = \"This is great!\"\n",
    "text3 = \"I wish for dead people in the future.\"\n",
    "text4 = \"I wish for dead people in the future and a lot of blood!\"\n",
    "text5 = \"What you say is total bull s***.\"\n",
    "text6 = \"Your mother is a big pile of feathers!\"\n",
    "text7 = \"I like a big pile of feathers!\"\n",
    "\n",
    "texts = [text1, text2, text3, text4, text5, text6, text7]\n",
    "\n",
    "# Running the texts through the first filter:\n",
    "%time results1 = [word_list_filter.apply(text) for text in texts]\n",
    "\n",
    "# Running the texts through the second filter:\n",
    "%time results2 = [detoxify_filter.apply(text) for text in texts]\n",
    "\n",
    "print(\"\")\n",
    "print(\"Results:\")\n",
    "print(f\" * WordListFilter: {results1}\")\n",
    "print(f\" * DetoxifyFilter: {results2}\")\n",
    "# filter2 returns 0 (non-toxic) or 1 (toxic).\n",
    "# Further insight into the classification is demonstrated below.\n",
    "# You can also specifiy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c24fcf0-b746-4651-9de9-f5a2fb1834c0",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3740e3bd-1a36-4ea1-a7d4-2ddb37328a14",
   "metadata": {},
   "source": [
    "**Since we setup the filter to keep the results, we can access them in post:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "843a76af-2fed-42f2-a8c2-ec194509664f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'This is shit!': {'toxic_token': 'shit'},\n",
       " 'This is great!': {'toxic_token': None},\n",
       " 'I wish for dead people in the future.': {'toxic_token': 'dead'},\n",
       " 'I wish for dead people in the future and a lot of blood!': {'toxic_token': 'dead'},\n",
       " 'What you say is total bull s***.': {'toxic_token': None},\n",
       " 'Your mother is a big pile of feathers!': {'toxic_token': None},\n",
       " 'I like a big pile of feathers!': {'toxic_token': None}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list_filter.get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9f09e58-3aa9-4204-9b28-77150abf3d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>This is shit!</th>\n",
       "      <td>0.97914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This is great!</th>\n",
       "      <td>0.00073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I wish for dead people in the future.</th>\n",
       "      <td>0.09880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I wish for dead people in the future and a lot of blood!</th>\n",
       "      <td>0.72205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>What you say is total bull s***.</th>\n",
       "      <td>0.92656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Your mother is a big pile of feathers!</th>\n",
       "      <td>0.91677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I like a big pile of feathers!</th>\n",
       "      <td>0.00215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    toxicity\n",
       "This is shit!                                        0.97914\n",
       "This is great!                                       0.00073\n",
       "I wish for dead people in the future.                0.09880\n",
       "I wish for dead people in the future and a lot ...   0.72205\n",
       "What you say is total bull s***.                     0.92656\n",
       "Your mother is a big pile of feathers!               0.91677\n",
       "I like a big pile of feathers!                       0.00215"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detoxify_filter.get_toxicity(as_dataframe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d19e5fbe-c34a-4bd4-8176-80c39f1b54d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxicity</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>This is shit!</th>\n",
       "      <td>0.97914</td>\n",
       "      <td>0.04470</td>\n",
       "      <td>0.92385</td>\n",
       "      <td>0.00223</td>\n",
       "      <td>0.11734</td>\n",
       "      <td>0.00252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This is great!</th>\n",
       "      <td>0.00073</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00018</td>\n",
       "      <td>0.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I wish for dead people in the future.</th>\n",
       "      <td>0.09880</td>\n",
       "      <td>0.00128</td>\n",
       "      <td>0.00168</td>\n",
       "      <td>0.03233</td>\n",
       "      <td>0.00238</td>\n",
       "      <td>0.00569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I wish for dead people in the future and a lot of blood!</th>\n",
       "      <td>0.72205</td>\n",
       "      <td>0.01523</td>\n",
       "      <td>0.01691</td>\n",
       "      <td>0.45062</td>\n",
       "      <td>0.02160</td>\n",
       "      <td>0.04721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>What you say is total bull s***.</th>\n",
       "      <td>0.92656</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.78472</td>\n",
       "      <td>0.00122</td>\n",
       "      <td>0.25074</td>\n",
       "      <td>0.00429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Your mother is a big pile of feathers!</th>\n",
       "      <td>0.91677</td>\n",
       "      <td>0.00410</td>\n",
       "      <td>0.13610</td>\n",
       "      <td>0.00082</td>\n",
       "      <td>0.74780</td>\n",
       "      <td>0.00612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I like a big pile of feathers!</th>\n",
       "      <td>0.00215</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>0.00022</td>\n",
       "      <td>0.00019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    toxicity  severe_toxicity  \\\n",
       "This is shit!                                        0.97914          0.04470   \n",
       "This is great!                                       0.00073          0.00012   \n",
       "I wish for dead people in the future.                0.09880          0.00128   \n",
       "I wish for dead people in the future and a lot ...   0.72205          0.01523   \n",
       "What you say is total bull s***.                     0.92656          0.01389   \n",
       "Your mother is a big pile of feathers!               0.91677          0.00410   \n",
       "I like a big pile of feathers!                       0.00215          0.00010   \n",
       "\n",
       "                                                    obscene   threat   insult  \\\n",
       "This is shit!                                       0.92385  0.00223  0.11734   \n",
       "This is great!                                      0.00020  0.00011  0.00018   \n",
       "I wish for dead people in the future.               0.00168  0.03233  0.00238   \n",
       "I wish for dead people in the future and a lot ...  0.01691  0.45062  0.02160   \n",
       "What you say is total bull s***.                    0.78472  0.00122  0.25074   \n",
       "Your mother is a big pile of feathers!              0.13610  0.00082  0.74780   \n",
       "I like a big pile of feathers!                      0.00020  0.00012  0.00022   \n",
       "\n",
       "                                                    identity_attack  \n",
       "This is shit!                                               0.00252  \n",
       "This is great!                                              0.00014  \n",
       "I wish for dead people in the future.                       0.00569  \n",
       "I wish for dead people in the future and a lot ...          0.04721  \n",
       "What you say is total bull s***.                            0.00429  \n",
       "Your mother is a big pile of feathers!                      0.00612  \n",
       "I like a big pile of feathers!                              0.00019  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detoxify_filter.get_scores(as_dataframe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd03076-fab6-4924-a4fc-5724d1bd90bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
